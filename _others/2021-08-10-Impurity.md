---
title: Impurity
author: Yu Donghwi
date: 2021-08-10
category: Jekyll
layout: post
---

### 1. Definition ###

Gradient descent는 target이 numerical할 때 사용되는 ML/DL 회귀 모델링의 최적화 메커니즘이다. 반면 불순도(Impurity)는 target이 categorical할 때 사용되는 ML/DL 분류 모델링의 최적화 메커니즘이다. Decision Tree는 각 Node에서 불순도를 최소화하는 분류 기준으로 가지치기를 진행하며 불순도를 측정하는 지표로 엔트로피 지수, 지니 지수, 카이제곱 통계량이 있다. 이때 root node부터 leaft node까지 불순도를 0으로 만드는 혹은 max_depth에 도달하는 과정에서 선택한 측정 지표를 일관되게 유지해야한다.

<br>

> ##### Information Gain
>
> information gain(정보 획득량) = 1 - impurity
{: .block-tip }




#### 1-1. Gini Index ####
경제학에서 사용하는 소득불평등도와 동일한 개념으로서 불균형에 대한 측도이다. 지니 지수가 클수록 불순도가 높아지며 측정 방식은 아래와 같다.

$$Gini = 1 - \sum_{i=1}^{n} (p_{i})^2$$

#### 1-2. Entropy Index ####
열역학에서 사용하는 자유도와 동일한 개념으로서 무질서에 대한 측도이다. 엔트로피 지수가 클수록 불순도가 높아지며 측정 방식은 아래와 같다.

$$Entropy = \sum_{i=1}^{n} -p_{i} \cdot (\log_{2}^{p_{i}})$$

#### 1-3. Chi square statistics ####
통계학에서 사용하는 적합성 검정의 통계량과 동일한 개념으로서 기대로부터의 오차에 대한 측도이다. 카이제곱 통계량이 클수록 불순도가 높아지며 측정 방식은 아래와 같다.

(k=범주의 수, O=관측 도수, B=기대 도수)

$$ \chi^2 = \sum_{i=1}^{k} \frac{(O_{i} - B_{i})^2}{B_{i}}$$




### 2. Example ###


#### Gini Index ####

> ##### 모형의 가정
>
> 각 노드에서 가지를 두 번만 치는 Binary Tree를 가정(e.g. sklearn)하여 학생의 성적을
{: .block-tip }

![](https://github.com/user-attachments/assets/3c6b5c0b-7ef8-4ccd-b130-bd99dfe7dd3a)


1. Impurity of root node

   $ I_{0} =  1 - (p_{합격})^2 - (p_{불합격})^2 $

   $ = 1 - (\frac{6}{10})^2 - (\frac{4}{10})^2 $

   $= 0.48$ 

2. Impurity of first node

2-1. 분류 기준 : 학습 방식 Left = {그룹 학습}, Right = {개인 학습, 온라인 학습}

   $I = 1 - p_{Left} \cdot (p_{합격|Left})^2 - p_{Left} \cdot (p_{불합격|Left})^2 -p_{Right} \cdot (p_{합격|Right})^2 - p_{Right} \cdot (p_{불합격|Right})^2$

   $ = 1 - p_{Left}\cdot((p_{합격|Left})^2 + (p_{불합격|Left})^2)- p_{Right}\cdot((p_{합격|Right})^2 + (p_{불합격|Right})^2) $

   $ = 1 - p_{Left} \cdlot (1-2 \cdot p_{합격|Left} \cdot p_{불합격|Left}) - p_{Right} \cdlot (1-2 \cdot p_{합격|Right} \cdot p_{불합격|Right}) $

   $ = 1 - p_{left} - p_{right} + 2 \cdot p_{Left} \cdot p_{합격|Left} \cdot p_{불합격|Left} + 2 \cdot p_{Right} \cdot p_{합격|Right} \cdot p_{불합격|Right} $

   $ = 2 \cdot (p_{Left} \cdot p_{합격|Left} \cdot p_{불합격|Left} + p_{Right} \cdot p_{합격|Right} \cdot p_{불합격|Right} ) $

   $ = 2 \cdot (0.8 + 0.12) $

   $ = 0.4$

2-2. 분류 기준 : 학습 방식 Left = {개인 학습}, Right = {그룹 학습, 온라인 학습}

   $I = 2 \cdot (p_{Left} \cdot p_{합격|Left} \cdot p_{불합격|Left} + p_{Right} \cdot p_{합격|Right} \cdot p_{불합격|Right} ) $

   $ = 2 \cdot (frac{1}{15} + \frac{1}{7}) $

   $ = 0.419 ... $

#### Entropy Index ####

> ##### 모형의 가정
>
> 각 노드에서 3개 이상의 가지를 칠 수 있는 Muli Branch Tree를 가정
{: .block-tip }








#### chis square statistics ####