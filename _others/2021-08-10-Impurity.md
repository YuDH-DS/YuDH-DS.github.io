---
title: Impurity
author: Yu Donghwi
date: 2021-08-10
category: Jekyll
layout: post
---

## 1. Definition ##

Gradient descent는 target이 numerical할 때 사용되는 ML/DL 회귀 모델링의 최적화 메커니즘이다. 반면 불순도(Impurity)는 target이 categorical할 때 사용되는 ML/DL 분류 모델링의 최적화 메커니즘이다. Decision Tree는 각 Node에서 불순도를 최소화하는 분류 기준으로 가지치기를 진행하며 불순도를 측정하는 지표로 엔트로피 지수, 지니 지수, 카이제곱 통계량이 있다. 이때 root node부터 leaft node까지 max_depth에 도달하는 과정에서 선택한 측정 지표를 일관되게 유지해야하며 max_depth에 이르지 않았더라도 불순도가 0이 되는 순간 학습은 종료된다.

<br>

> ##### Information Gain
>
> information gain(정보 획득량) = 1 - impurity
> $ IG = 1 - I $
{: .block-tip }




### 1-1. Gini Index ###
경제학에서 사용하는 소득불평등도와 동일한 개념으로서 불균형에 대한 측도이다. 지니 지수가 클수록 불순도가 높아지며 측정 방식은 아래와 같다.

$$Gini = 1 - \sum_{i=1}^{n} (p_{i})^2$$

### 1-2. Entropy Index ###
열역학에서 사용하는 자유도와 동일한 개념으로서 무질서에 대한 측도이다. 엔트로피 지수가 클수록 불순도가 높아지며 측정 방식은 아래와 같다.

$$Entropy = \sum_{i=1}^{n} -p_{i} \cdot (\log_{2}^{p_{i}})$$

### 1-3. Chi square statistics ###
통계학에서 사용하는 적합성 검정의 통계량과 동일한 개념으로서 기대로부터의 오차에 대한 측도이다. 카이제곱 통계량이 클수록 불순도가 높아지며 측정 방식은 아래와 같다.

(k=범주의 수, O=관측 도수, B=기대 도수)

$$ \chi^2 = \sum_{i=1}^{k} \frac{(O_{i} - B_{i})^2}{B_{i}}$$




## 2. Example ##


### Gini Index ###

> ##### 모형의 가정
>
> 각 노드에서 가지를 두 번만 치는 Binary Tree를 가정(e.g. sklearn)하여 학생의 성적을 분류하는 모델을 설계한다.
> (소수점 둘째자리까지 반올림)
{: .block-tip }

![](https://github.com/user-attachments/assets/3c6b5c0b-7ef8-4ccd-b130-bd99dfe7dd3a)


#### Impurity of root node ####

   $ I_{0} =  1 - (P_{합격})^2 - (P_{불합격})^2 $

   $ = 1 - (\frac{6}{10})^2 - (\frac{4}{10})^2 $

   $= 0.48$ 

#### Impurity of first node #####

##### 분류 기준 : 학습 방식 Left = {그룹 학습}, Right = {개인 학습, 온라인 학습} #####

   $ I = 1 - P_{Left} \cdot (P_{합격 \vert Left})^2 - P_{Left} \cdot (P_{불합격 \vert Left})^2 -P_{Right} \cdot (P_{합격 \vert Right})^2 - P_{Right} \cdot (P_{불합격 \vert Right})^2 $

   $ = 1 - P_{Left}\cdot((P_{합격 \vert Left})^2 + (P_{불합격 \vert Left})^2)- P_{Right}\cdot((P_{합격 \vert Right})^2 + (P_{불합격 \vert Right})^2) $

   $ = 1 - P_{Left} \cdot (1-2 \cdot P_{합격 \vert Left} \cdot P_{불합격 \vert Left}) - P_{Right} \cdot (1-2 \cdot P_{합격 \vert Right} \cdot P_{불합격 \vert Right}) $

   $ = 1 - P_{left} - P_{right} + 2 \cdot P_{Left} \cdot P_{합격 \vert Left} \cdot P_{불합격 \vert Left} + 2 \cdot P_{Right} \cdot P_{합격 \vert Right} \cdot P_{불합격 \vert Right} $

   $ = 2 \cdot (P_{Left} \cdot P_{합격 \vert Left} \cdot P_{불합격 \vert Left} + P_{Right} \cdot P_{합격 \vert Right} \cdot P_{불합격 \vert Right} ) $

   $ = 2 \cdot (0.8 + 0.12) $

   $ = 0.4 $

   <br>

   $ IG = 0.48 - 0.4 = 0.08 $

##### 분류 기준 : 학습 방식 Left = {개인 학습}, Right = {그룹 학습, 온라인 학습} #####

   $ I = 2 \cdot (P_{Left} \cdot P_{합격 \vert Left} \cdot P_{불합격 \vert Left} + P_{Right} \cdot P_{합격 \vert Right} \cdot P_{불합격 \vert Right} ) $

   $ = 2 \cdot (\frac{1}{15} + \frac{1}{7}) $

   $ = 0.419 ... $

   <br>

   $ IG = 0.48 - 0.42 = 0.06 $

##### 분류 기준 : 학습 방식 Left = {온라인 학습}, Right = {그룹 학습, 개인 학습} #####

   $ I = 2 \cdot (P_{Left} \cdot P_{합격 \vert Left} \cdot P_{불합격 \vert Left} + P_{Right} \cdot P_{합격 \vert Right} \cdot P_{불합격 \vert Right} ) $

   $ = 2 \cdot (\frac{1}{20} + \frac{3}{16}) $

   $ = 0.475 $

   <br>

   $ IG = 0.48 - 0.48 = 0 $

##### 분류 기준 : 과목 Left = {수학}, Right = {영어, 과학} #####

   $ I = 2 \cdot (P_{Left} \cdot P_{합격 \vert Left} \cdot P_{불합격 \vert Left} + P_{Right} \cdot P_{합격 \vert Right} \cdot P_{불합격 \vert Right} ) $

   $ = 2 \cdot (\frac{1}{15} + \frac{6}{35}) $

   $ = 0.476... $

   <br>

   $ IG = 0.48 - 0.48 = 0 $

##### 분류 기준 : 과목 Left = {영어}, Right = {수학, 과학} #####

   $ I = 2 \cdot (P_{Left} \cdot P_{합격 \vert Left} \cdot P_{불합격 \vert Left} + P_{Right} \cdot P_{합격 \vert Right} \cdot P_{불합격 \vert Right} ) $

   $ = 2 \cdot (0 + \frac{3}{35}) $

   $ = 0.171... $

   <br>

   $ IG = 0.48 - 0.17 = 0.31 $

##### 분류 기준 : 과목 Left = {과학}, Right = {영어, 수학} #####

   $ I = 2 \cdot (P_{Left} \cdot P_{합격 \vert Left} \cdot P_{불합격 \vert Left} + P_{Right} \cdot P_{합격 \vert Right} \cdot P_{불합격 \vert Right} ) $

   $ = 2 \cdot (0 + \frac{2}{15}) $

   $ = 0.266... $

<br>

   $ IG = 0.48 - 0.27 = 0.21 $

##### 소결

![](https://github.com/user-attachments/assets/15dd0cdc-cc56-4e6d-a4a3-8bd44bd9d7e5)


First node : Left = {영어}, Right = {수학, 과학}
IG = 0.31

불순도가 가장 적어 가장 많은 정보를 획득하는 분류 기준에 따라 영어 학습 여부에 따라 학생들을 분류하였다.

그 결과 첫 단계에서 영어를 수강한 3명의 학생이 '불합격'으로 분류 되어 Left side from first node의 학습은 종료된다.

#### Impurity of second node #####

##### Right side data from first node #####

![](https://github.com/user-attachments/assets/6c3b7626-c0a7-4b8b-b9ff-bd377e727502)

##### 분류 기준 : 학습 방식 Left = {그룹 학습}, Right = {개인 학습, 온라인 학습} #####

   $ I = 2 \cdot (P_{Left} \cdot P_{합격 \vert Left} \cdot P_{불합격 \vert Left} + P_{Right} \cdot P_{합격 \vert Right} \cdot P_{불합격 \vert Right} ) $

   $ = 2 \cdot (0 + \frac{2}{21}) $

   $ = 0.190 ... $
   
<br>

   $ IG = 0.17 - 0.19 = -0.02... $

##### 분류 기준 : 학습 방식 Left = {온라인 학습}, Right = {개인 학습, 그룹 학습} #####

   $ I = 2 \cdot (P_{Left} \cdot P_{합격 \vert Left} \cdot P_{불합격 \vert Left} + P_{Right} \cdot P_{합격 \vert Right} \cdot P_{불합격 \vert Right} ) $

   $ = 2 \cdot (0 + \frac{5}{42}) $

   $ = 0.238 ... $
   
<br>

   $ IG = 0.17 - 0.24 = -0.07... $

##### 분류 기준 : 학습 방식 Left = {온라인 학습}, Right = {개인 학습, 그룹 학습} #####

   $ I = 2 \cdot (P_{Left} \cdot P_{합격 \vert Left} \cdot P_{불합격 \vert Left} + P_{Right} \cdot P_{합격 \vert Right} \cdot P_{불합격 \vert Right} ) $

   $ = 2 \cdot (\frac{1}{14} + 0) $

   $ = 0.142... $
   
<br>

   $ IG = 0.17 - 0.14 = 0.03... $

##### 분류 기준 : 과목 Left = {수학}, Right = {과학} #####

   $ I = 2 \cdot (P_{Left} \cdot P_{합격 \vert Left} \cdot P_{불합격 \vert Left} + P_{Right} \cdot P_{합격 \vert Right} \cdot P_{불합격 \vert Right} ) $

   $ = 2 \cdot (\frac{2}{21} + 0) $

   $ = 0.190... $
   
<br>

   $ IG = 0.17 - 0.19 = -0.02... $

##### 소결

![](https://github.com/user-attachments/assets/c0a9b38d-70e2-48cb-8f2d-985719bae2cc)


Second node : Left = {개인 학습}, Right = {온라인 학습, 그룹 학습}
IG = 0.03

불순도가 가장 적어 가장 많은 정보를 획득하는 분류 기준에 따라 개인 학습을 하는지 여부 따라 학생들을 분류하였다.

그 결과 두 번째 단계에서 개인 학습을 하는 5명의 학생이 '합격'으로 분류 되어 Right side from second node의 학습은 종료된다.

#### Impurity of third node #####

##### Left side data from first node #####

![](https://github.com/user-attachments/assets/a369f1d9-5751-48a6-a3d6-df0ea4a2fd42)

#### Impurity of third node #####

![](https://github.com/user-attachments/assets/91d16738-e6ae-4c4b-8312-97e8446a2150)


불순도가 0이 되어 학습이 종료되어 위와 같은 Decision tree 모형이 완성되었다.
이후 모델은 새로운 데이터에 대해서도 이와 같은 절차를 걸쳐 분류 결과 예측치를 제공한다.


#### Entropy Index ####

> ##### 모형의 가정
>
> 각 노드에서 3개 이상의 가지를 칠 수 있는 Muli Branch Tree를 가정
{: .block-tip }









#### chis square statistics ####